# Copyright Â© Advanced Micro Devices, Inc., or its affiliates.
#
# SPDX-License-Identifier: MIT

com:
  amd:
    aim:
      model:
        canonicalName: "meta-llama/Llama-3.1-8B-Instruct"
        tags:
        - "text-generation"
        - "chat"
        - "instruction"
        source: "https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct"
        variants:
        - "amd/Llama-3.1-8B-Instruct-FP8-KV"
        - "meta-llama/Llama-3.1-8B-Instruct"
        recommendedDeployments:
        - gpuModel: "MI300X"
          gpuCount: 1
          precision: "fp8"
          metric: "latency"
          description: "Optimized for latency on MI300X using fp8 precision"
        - gpuModel: "MI300X"
          gpuCount: 1
          precision: "fp8"
          metric: "throughput"
          description: "Optimized for throughput on MI300X using fp8 precision"
        - gpuModel: "MI325X"
          gpuCount: 1
          metric: "latency"
          description: "Optimized for latency on MI325X using fp8 precision"
          profileId: "vllm-mi325x-fp8-tp1-latency"
        - gpuModel: "MI325X"
          gpuCount: 1
          metric: "throughput"
          description: "Optimized for throughput on MI325X using fp8 precision"
          profileId: "vllm-mi325x-fp8-tp1-throughput"
        publisher: "Meta"
      hfToken:
        required: true
      release:
        notes: ""
      description:
        full: "Meta Llama 3.1 8B model optimized for chat and instruction following. Built on transformer architecture with GQA and RLHF training."
      title: "Llama 3.1 8B Instruct"
org:
  opencontainers:
    image:
      vendor: "AMD"
      authors: ""
      licenses: "llama3.1, MIT"
      description: "Meta Llama 3.1 8B model optimized for chat and instruction following. Built on transformer architecture with GQA and RLHF training."
      documentation: ""
      source: "https://github.com/amd-enterprise-ai/aim-build"
