# Copyright Â© Advanced Micro Devices, Inc., or its affiliates.
#
# SPDX-License-Identifier: MIT

org:
  opencontainers:
    image:
      vendor: "AMD"
      authors: ""
      licenses: "Apache-2.0, MIT"
      description: "Mixture of experts model with 8 experts of 7B parameters each for efficient scaling."
      documentation: ""
      source: "https://github.com/amd-enterprise-ai/aim-build"
com:
  amd:
    aim:
      model:
        canonicalName: "mistralai/Mixtral-8x7B-Instruct-v0.1"
        tags:
        - "text-generation"
        - "chat"
        source: "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1"
        variants:
        - "mistralai/Mixtral-8x7B-Instruct-v0.1"
        recommendedDeployments:
        - gpuModel: "MI300X"
          gpuCount: 1
          precision: "fp16"
          metric: "latency"
          description: "Optimized for latency on MI300X using fp16 precision"
        - gpuModel: "MI300X"
          gpuCount: 1
          precision: "fp16"
          metric: "throughput"
          description: "Optimized for throughput on MI300X using fp16 precision"
        - gpuModel: "MI325X"
          gpuCount: 1
          metric: "latency"
          description: "Optimized for latency on MI325X using fp16 precision"
          profileId: "vllm-mi325x-fp16-tp1-latency"
        - gpuModel: "MI325X"
          gpuCount: 1
          metric: "throughput"
          description: "Optimized for throughput on MI325X using fp16 precision"
          profileId: "vllm-mi325x-fp16-tp1-throughput"
        publisher: "Mistral AI"
      hfToken:
        required: false
      release:
        notes: ""
      description:
        full: "Mixture of experts model with 8 experts of 7B parameters each for efficient scaling."
      title: "Mixtral 8x7B Instruct v0.1"
